{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Preprocesamiento** **de** **los** **datos** **de** **entrenamiento** **de** **los** **modelos** **NLP**\n",
        "En este módulo se lleva a cabo el preprocesamiento de los datos que servirán como entrada para el entrenamiento de los modelos de Procesamiento de Lenguaje Natural (PLN) utilizados en nuestra aplicación.\n",
        "\n",
        "La fuente primaria de datos está conformada por recetas de cocina extraídas del portal elmundo.es, lo que garantiza un corpus extenso y heterogéneo en idioma español.\n",
        "\n",
        "El pipeline de preprocesamiento comprende las siguientes etapas:\n",
        "\n",
        "1. Extracción de datos mediante  scraping automatizado de recetas directamente desde la web.\n",
        "\n",
        "2. Preprocesamiento y enriquecimiento: Limpieza, normalización y estructuración de los textos obtenidos.\n",
        "\n",
        "3. Generación de dataset etiquetado: Utilización de prompting mediante la API de OpenAI para obtener conjuntos de datos con anotaciones específicas orientadas a tareas de clasificación y reconocimiento de entidades nombradas (NER)."
      ],
      "metadata": {
        "id": "KrzjN3LBvze2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62SPIbhTVqw2",
        "outputId": "1b25b1be-1363-4532-e05c-ac895e6ed4d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.14.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unidecode\n",
            "  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading Unidecode-1.4.0-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install requests beautifulsoup4 pandas\n",
        "!pip install -q openai ipywidgets python-dotenv\n",
        "!pip install unidecode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from openai import OpenAI\n",
        "import os\n",
        "import json"
      ],
      "metadata": {
        "id": "nKIwyV2Pmjj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El flujo de preprocesamiento será el siguiente:\n",
        "\n",
        "1)Scrapping de todas las páginas que contengan recetas. Debido a que en la web hay entradas que no contienen recetas en sí, se considerará como receta aquella que contenga una lista de ingredientes\n",
        "\n",
        "2)Prompting de la página para obtener de ella una lista de ingredientes y una lista de pasos de la receta\n",
        "\n",
        "3)Procesamiento de la lista de pasos: con ello se obtiene un texto unificado de la receta a partir de la secuencia de pasos de la misma.\n",
        "\n",
        "4)Definición de los spans de las distintas etiquetas(ingredientes) de cada receta.\n",
        "\n",
        "6)Obtención del dataset de entrenamiento, en el cual cada receta tiene un texto con la receta y la lista de spans\n"
      ],
      "metadata": {
        "id": "vAiqL382x36S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])"
      ],
      "metadata": {
        "id": "AOooefnHiW3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No todas las entradas de la webse corresponden con recetas. Algunas entradas contienen consejos de cocina, etc. Para extraer aquellas entradas que sí se corresponden con recetas, se ha observado un patrón que contienen todas estas: un listado de ingredientes. Con la función ***extraer_ingredientes*** extraemos esta lista de ingredientes, lo cual nos permitirá evaluar si la página es de una receta o no."
      ],
      "metadata": {
        "id": "8ph97K4W7Iml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Función que extrae de la web la lista de ingredientes, de haberla. Necesaria para filtrar aquellas webs que nos sirven de las que no\n",
        "def extraer_ingredientes(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        if response.status_code != 200:\n",
        "            return []\n",
        "\n",
        "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "        # Buscar cualquier etiqueta que contenga \"ingredientes\"\n",
        "        posibles_encabezados = [\n",
        "            tag for tag in soup.find_all(True)\n",
        "            if tag.get_text(strip=True).lower().startswith(\"ingredientes\")\n",
        "        ]\n",
        "\n",
        "        ingredientes = []\n",
        "\n",
        "        for encabezado in posibles_encabezados:\n",
        "            bloque = encabezado.find_next(\"ul\")\n",
        "            if bloque:\n",
        "                ingredientes += [li.get_text(strip=True) for li in bloque.find_all(\"li\")]\n",
        "\n",
        "        return ingredientes\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", e)\n",
        "        return []"
      ],
      "metadata": {
        "id": "W_V1hY2h63q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La siguiente función sirve para procesar mediante un prompt a Open AI las recetas de la web. La receta procesada consistira en un diccionario con las siguientes claves:\n",
        "\n",
        "- Título de la receta\n",
        "\n",
        "- URL\n",
        "\n",
        "-Ingredientes que aparecen en la receta (etiquetas que usaremos posteriormente en el modelo NER)\n",
        "\n",
        "\n",
        "-Pasos de la receta (nos servirá para entrenar el modelo de clasificación)\n",
        "\n"
      ],
      "metadata": {
        "id": "ShtjkvT67r3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Función procesamiento de las recetas, obteniendo de cada una de ellas: titulo, url, ingredientes y pasos\n",
        "def procesar_receta_con_gpt(url, max_chars_html=20000):\n",
        "    try:\n",
        "        r = requests.get(url, timeout=20)\n",
        "        if r.status_code != 200:\n",
        "            print(f\"Error al acceder a {url}: {r.status_code}\")\n",
        "            return None\n",
        "\n",
        "        # Texto plano del HTML (recorta para no mandar un libro al modelo)\n",
        "        texto_receta = BeautifulSoup(r.content, \"html.parser\").get_text(\" \", strip=True)\n",
        "        if len(texto_receta) > max_chars_html:\n",
        "            texto_receta = texto_receta[:max_chars_html]\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "Responde SOLO con un JSON válido, sin texto extra.\n",
        "\n",
        "Esquema exacto:\n",
        "{{\n",
        "  \"ingredientes\": [\"...\", \"...\", \"...\"],\n",
        "  \"pasos\": [\"...\", \"...\"]\n",
        "}}\n",
        "\n",
        "Reglas:\n",
        "- \"ingredientes\": lista deduplicada de NOMBRES (solo sustantivos) en minúsculas, sin cantidades, unidades, marcas ni adjetivos.\n",
        "  Normalización:\n",
        "  * Recorta espacios, elimina tildes para comparar, devuelve con tildes si aparecen en la fuente (p. ej., “azúcar”).\n",
        "  * Singulariza plurales simples (“tomates”→“tomate”, “cebollas”→“cebolla”).\n",
        "  * Compósitos: conserva la forma más informativa en el orden canónico (p. ej., “aceite de oliva”, “vinagre de manzana”, “azúcar glas”).\n",
        "  * Quita calificativos/adjetivos no nucleares (“grande”, “picada”, “fresco”, “virgen extra”) salvo que definan el compuesto (“azúcar glas”, “leche evaporada”).\n",
        "  * Unidades/cantidades fuera (“2 cda”, “200 g”, “1/2 taza”, “ml”, “kg”, “c/s”).\n",
        "  * Sinónimos/abreviaturas comunes → forma canónica: “aove”→“aceite de oliva”; “azúcar glass/azúcar en polvo”→“azúcar glas”; “bicarbonato sódico”→“bicarbonato”.\n",
        "  * Deduplica tras normalizar.\n",
        "  *Incluye TODOS los ingredientes que se detecten en la receta, aunque no estén en la lista de ingredientes** (por ejemplo, mencionados solo en los pasos).\n",
        "  Orden: por la PRIMERA aparición del ingrediente en los “pasos” (índices 1..N).\n",
        "\n",
        "- Detección y agrupado de pasos:\n",
        "  * Si la receta trae numeración explícita (p. ej., \"Paso 1\", \"1.\", \"1)\", \"1.-\"):\n",
        "    - Conserva TODOS los pasos en el MISMO orden de la fuente. NO renumeres.\n",
        "    - Todo el texto CONTIGUO desde un marcador de paso hasta el siguiente marcador pertenece al MISMO paso. No lo dividas aunque tenga varias frases o párrafos; únelas en un único string limpio.\n",
        "    - Puede haber pasos que no mencionen ingredientes; se mantienen igualmente.\n",
        "  * Si NO hay numeración explícita, segmenta en pasos breves por orden lógico y numéralos 1..N.\n",
        "\n",
        "- \"pasos\": lista ordenada de textos de paso (una frase breve por paso). Si hay numeración explícita, debe corresponder 1:1 con los pasos originales.\n",
        "Ejemplo:\n",
        "Texto: \"Ingredientes:Cebolla. Paso 1: Corta la cebolla. Paso 2: Mezcla la cebolla con el tomate. Paso 3: Sirve.\"\n",
        "Salida:\n",
        "{{\n",
        "  \"ingredientes\": [\"cebolla\",\"tomate\"],\n",
        "  \"pasos\": [\"Corta la cebolla.\",\"Mezcla la cebolla con el tomate.\",\"Sirve.\"],\n",
        "}}\n",
        "\n",
        "Texto de la receta:\n",
        "\\\"\\\"\\\"{texto_receta}\\\"\\\"\\\"\n",
        "\"\"\".strip()\n",
        "\n",
        "        resp = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            temperature=0,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"Eres estricto: solo devuelves JSON válido exactamente como se solicita.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt},\n",
        "            ],\n",
        "        )\n",
        "\n",
        "        content = resp.choices[0].message.content  # <- clave del bug\n",
        "\n",
        "        # Intentar parsear JSON directamente\n",
        "        try:\n",
        "            data = json.loads(content)\n",
        "            return data\n",
        "        except json.JSONDecodeError:\n",
        "            # Intento de extracción de bloque JSON si vino con texto extra\n",
        "            match = re.search(r\"\\{.*\\}\", content, flags=re.DOTALL)\n",
        "            if match:\n",
        "                try:\n",
        "                    return json.loads(match.group(0))\n",
        "                except json.JSONDecodeError:\n",
        "                    pass\n",
        "            print(\"No se pudo parsear JSON desde la salida del modelo.\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error en procesar_receta_con_gpt:\", e)\n",
        "        return None"
      ],
      "metadata": {
        "id": "4EVLl9E6jQHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de aplicar el pipeline de scrapping + procesamiento por prompting de las recetas, necesitamos definir esta la función auxiliar *normalizar_url* que Nos servirá para no procesar mas de una vez la misma url,ya el scrapping se hace recorriendo página a página la web y existen entradas que se repiten en distintas páginas (por ejemplo, la entrada \"gazpacho\" podría encontrarse en la página \"Recetas españolas\" y en la páhgina \"recetas de verano\", por lo que si no usamos esta función tendríamos dos recetas idénticas repetidas en nuestro dataset de entrenamiento."
      ],
      "metadata": {
        "id": "D4Zuwh7R8tho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Funcion para normalizar urls. Nos servirá para no procesar mas de una vez la misma url\n",
        "from urllib.parse import urlsplit, urlunsplit\n",
        "\n",
        "def normalizar_url(u: str) -> str:\n",
        "    s = urlsplit(u.strip())\n",
        "    scheme = (s.scheme or \"https\").lower()\n",
        "    netloc = s.netloc.lower()\n",
        "    path = s.path.rstrip(\"/\")\n",
        "    return urlunsplit((scheme, netloc, path, \"\", \"\"))  # sin query ni fragmento"
      ],
      "metadata": {
        "id": "V3v0qll6T3oO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con las funciones anteriormente descritas aplicamos un pipeline a las siguientes páginas de la web:\n",
        "\n",
        "- Recetas faciles\n",
        "\n",
        "- Recetas rapidas\n",
        "\n",
        "- Recetas sanas\n",
        "\n",
        "- Recetas pollo\n",
        "\n",
        "- Recetas pasta\n",
        "\n",
        "- Recetas carne\n",
        "\n",
        "- Recetas pescado\n",
        "\n",
        "- Recetas verdura\n",
        "\n",
        "Obteniendo un corpus inicial de 1189 recetas.\n",
        "\n"
      ],
      "metadata": {
        "id": "sUm0psrK9njc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Primer set de recetas\n",
        "base_url = \"https://recetasdecocina.elmundo.es/recetas/faciles\"\n",
        "recetas = []\n",
        "max_paginas = 10\n",
        "vistas_url = set()\n",
        "\n",
        "for page in range(1, max_paginas + 1):\n",
        "    url = base_url if page == 1 else f\"{base_url}/page/{page}\"\n",
        "    print(f\" Visitando: {url}\")\n",
        "\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        print(f\" Error al acceder a la página {page}\")\n",
        "        break\n",
        "\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    enlaces = soup.find_all(\"a\", attrs={\"rel\": \"bookmark\"})\n",
        "    if not enlaces:\n",
        "        print(\" No se encontraron recetas en esta página. Fin.\")\n",
        "        break\n",
        "\n",
        "    nuevas = 0\n",
        "    for a in enlaces:\n",
        "        href = a.get(\"href\")\n",
        "        title = a.get(\"title\")\n",
        "        if not href or not title:\n",
        "            continue\n",
        "\n",
        "        href_norm = normalizar_url(href)\n",
        "        if href_norm in vistas_url:\n",
        "            continue  # ya la procesaste\n",
        "\n",
        "\n",
        "        ingredientes_previos = extraer_ingredientes(href_norm)\n",
        "        if not ingredientes_previos:\n",
        "          continue\n",
        "\n",
        "        datos_gpt = procesar_receta_con_gpt(href_norm)\n",
        "        if not datos_gpt:\n",
        "            continue\n",
        "\n",
        "        receta = {\n",
        "            \"titulo\": title.strip(),\n",
        "            \"url\": href_norm,  # guarda la URL normalizada\n",
        "            \"ingredientes\": datos_gpt.get(\"ingredientes\", []),\n",
        "            \"pasos\": datos_gpt.get(\"pasos\", [])\n",
        "        }\n",
        "        recetas.append(receta)\n",
        "        vistas_url.add(href_norm)\n",
        "        nuevas += 1\n",
        "\n",
        "    print(f\" Se añadieron {nuevas} recetas con ingredientes.\\n\")\n",
        "    if nuevas == 0:\n",
        "        print(\" No hay recetas nuevas con ingredientes. Fin del scraping.\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlW1Q8T4kHyT",
        "outputId": "d4723487-cdf2-4794-cb12-7289cd2c2d17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Visitando: https://recetasdecocina.elmundo.es/recetas/faciles\n",
            " Se añadieron 20 recetas con ingredientes.\n",
            "\n",
            " Visitando: https://recetasdecocina.elmundo.es/recetas/faciles/page/2\n",
            " Se añadieron 20 recetas con ingredientes.\n",
            "\n",
            " Visitando: https://recetasdecocina.elmundo.es/recetas/faciles/page/3\n",
            " Se añadieron 19 recetas con ingredientes.\n",
            "\n",
            " Visitando: https://recetasdecocina.elmundo.es/recetas/faciles/page/4\n",
            " Se añadieron 20 recetas con ingredientes.\n",
            "\n",
            " Visitando: https://recetasdecocina.elmundo.es/recetas/faciles/page/5\n",
            " Se añadieron 19 recetas con ingredientes.\n",
            "\n",
            " Visitando: https://recetasdecocina.elmundo.es/recetas/faciles/page/6\n",
            " Se añadieron 19 recetas con ingredientes.\n",
            "\n",
            " Visitando: https://recetasdecocina.elmundo.es/recetas/faciles/page/7\n",
            " Se añadieron 12 recetas con ingredientes.\n",
            "\n",
            " Visitando: https://recetasdecocina.elmundo.es/recetas/faciles/page/8\n",
            " Error al acceder a la página 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sucesivos set de recetas\n",
        "base_url = \"https://recetasdecocina.elmundo.es/recetas/verduras\"\n",
        "max_paginas = 45\n",
        "\n",
        "\n",
        "for page in range(1, max_paginas + 1):\n",
        "    url = base_url if page == 1 else f\"{base_url}/page/{page}\"\n",
        "    print(f\" Visitando: {url}\")\n",
        "\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        print(f\" Error al acceder a la página {page}\")\n",
        "        break\n",
        "\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    enlaces = soup.find_all(\"a\", attrs={\"rel\": \"bookmark\"})\n",
        "    if not enlaces:\n",
        "        print(\" No se encontraron recetas en esta página. Fin.\")\n",
        "        break\n",
        "\n",
        "    nuevas = 0\n",
        "    for a in enlaces:\n",
        "        href = a.get(\"href\")\n",
        "        title = a.get(\"title\")\n",
        "        if not href or not title:\n",
        "            continue\n",
        "\n",
        "        href_norm = normalizar_url(href)\n",
        "        if href_norm in vistas_url:\n",
        "            continue  # ya la procesaste\n",
        "\n",
        "\n",
        "        ingredientes_previos = extraer_ingredientes(href_norm)\n",
        "        if not ingredientes_previos:\n",
        "          continue\n",
        "\n",
        "        datos_gpt = procesar_receta_con_gpt(href_norm)\n",
        "        if not datos_gpt:\n",
        "            continue\n",
        "\n",
        "        receta = {\n",
        "            \"titulo\": title.strip(),\n",
        "            \"url\": href_norm,  # guarda la URL normalizada\n",
        "            \"ingredientes\": datos_gpt.get(\"ingredientes\", []),\n",
        "            \"pasos\": datos_gpt.get(\"pasos\", [])\n",
        "        }\n",
        "        recetas.append(receta)\n",
        "        vistas_url.add(href_norm)\n",
        "        nuevas += 1\n",
        "\n",
        "    print(f\" Se añadieron {nuevas} recetas con ingredientes.\\n\")\n",
        "    if nuevas == 0:\n",
        "        print(\" No hay recetas nuevas con ingredientes. Fin del scraping.\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Inq1qyXBPS7Q",
        "outputId": "aeff4994-5a4c-40f7-b115-2cda4c87ffa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Visitando: https://recetasdecocina.elmundo.es/recetas/verduras\n",
            " Se añadieron 1 recetas con ingredientes.\n",
            "\n",
            " Visitando: https://recetasdecocina.elmundo.es/recetas/verduras/page/2\n",
            " Se añadieron 1 recetas con ingredientes.\n",
            "\n",
            " Visitando: https://recetasdecocina.elmundo.es/recetas/verduras/page/3\n",
            " Se añadieron 1 recetas con ingredientes.\n",
            "\n",
            " Visitando: https://recetasdecocina.elmundo.es/recetas/verduras/page/4\n",
            " Se añadieron 4 recetas con ingredientes.\n",
            "\n",
            " Visitando: https://recetasdecocina.elmundo.es/recetas/verduras/page/5\n",
            " Se añadieron 1 recetas con ingredientes.\n",
            "\n",
            " Visitando: https://recetasdecocina.elmundo.es/recetas/verduras/page/6\n",
            " Se añadieron 3 recetas con ingredientes.\n",
            "\n",
            " Visitando: https://recetasdecocina.elmundo.es/recetas/verduras/page/7\n",
            " Se añadieron 4 recetas con ingredientes.\n",
            "\n",
            " Visitando: https://recetasdecocina.elmundo.es/recetas/verduras/page/8\n",
            " Se añadieron 1 recetas con ingredientes.\n",
            "\n",
            " Visitando: https://recetasdecocina.elmundo.es/recetas/verduras/page/9\n",
            " Se añadieron 3 recetas con ingredientes.\n",
            "\n",
            " Visitando: https://recetasdecocina.elmundo.es/recetas/verduras/page/10\n",
            " Se añadieron 4 recetas con ingredientes.\n",
            "\n",
            " Visitando: https://recetasdecocina.elmundo.es/recetas/verduras/page/11\n",
            " Se añadieron 10 recetas con ingredientes.\n",
            "\n",
            " Visitando: https://recetasdecocina.elmundo.es/recetas/verduras/page/12\n",
            " Se añadieron 12 recetas con ingredientes.\n",
            "\n",
            " Visitando: https://recetasdecocina.elmundo.es/recetas/verduras/page/13\n",
            " Se añadieron 3 recetas con ingredientes.\n",
            "\n",
            " Visitando: https://recetasdecocina.elmundo.es/recetas/verduras/page/14\n",
            " Error al acceder a la página 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(recetas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAbWPYZHBBPz",
        "outputId": "ab33e87e-6d76-496b-e046-8333175bc691"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1189"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardamos el recetario procesado en formato json"
      ],
      "metadata": {
        "id": "X9tkjugv-35y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "#guardamos la lista con las recetas procesadas\n",
        "Path(\"recetas.json\").write_text(\n",
        "    json.dumps(recetas, ensure_ascii=False, indent=2),\n",
        "    encoding=\"utf-8\"\n",
        ")"
      ],
      "metadata": {
        "id": "uSMoJnzg_B3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Leerlo de vuelta\n",
        "contenido = Path(\"recetas.json\").read_text(encoding=\"utf-8\")\n",
        "recetas_cargadas = json.loads(contenido)"
      ],
      "metadata": {
        "id": "oYqX0PTgJDbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como se ha mencionado anteriormente, el corpus es una lista de diccionarios en la que cada diccionario corresponde una receta. A modo de ejemplo se muestra una entrada de la lista, correspondiente a la receta \"Pochas copn pollo de corral\""
      ],
      "metadata": {
        "id": "0Y0ltj0f_r5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recetas_cargadas[752]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0mqKijnJJoB",
        "outputId": "2b254823-1f72-4b9b-e62c-c9a9c9da3790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'titulo': 'Pochas con pollo de corral, una receta sana y casera',\n",
              " 'url': 'https://recetasdecocina.elmundo.es/2021/01/pochas-pollo-corral-receta-sana-casera.html',\n",
              " 'ingredientes': ['pollo',\n",
              "  'ajo',\n",
              "  'pimiento rojo',\n",
              "  'pimiento verde',\n",
              "  'cebolleta',\n",
              "  'tomate frito',\n",
              "  'pimentón',\n",
              "  'zanahoria',\n",
              "  'pochas',\n",
              "  'azafrán',\n",
              "  'caldo',\n",
              "  'sal'],\n",
              " 'pasos': ['Comenzamos haciendo el sofrito. Pochamos las verduras cortadas muy finamente. Durante unos 20 minutos a fuego lento. Cuando tengamos las verduras pochadas ponemos unas hebras de azafrán y un poco de pimentón que le van a dar un toque espectacular.',\n",
              "  'Mientras tanto en una sartén, doramos los trozos. Previamente los hemos tenido que salpimentar. Una vez dorados, retiramos y reservamos.',\n",
              "  'Cuando este el sofrito, agregamos el pollo dorado, las pochas frescas y cubrimos con caldo de pollo.',\n",
              "  'Cocinamos durante unos 20 minutos a fuego lento.']}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nuestro objetivo con el modelo de clasificación de oraciones es agrupar las oraciones en pasos, identificando en ellas patrones que permitan al modelo discernir si una oración pertenece a un nuevo paso o es parte de un paso anterior. Para entrenar este modelo, el input propuesto para cada receta es un texto que contenga la receta de seguido, sin pasos. A este texto le llamaremos \"resumen\" y será una nueva entrada del diccionario de cada receta. Para obtenerlo definimos la función ***agregar_resumen_a_receta***."
      ],
      "metadata": {
        "id": "8qmMufQGAGUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Funcion para añadir resumen a la receta\n",
        "import re\n",
        "from typing import Dict, List, Any\n",
        "\n",
        "def agregar_resumen_a_receta(receta: Dict[str, Any], clave_pasos: str = \"pasos\", clave_resumen: str = \"resumen\") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Añade receta[clave_resumen] uniendo receta[clave_pasos] (lista de strings)\n",
        "    en una sola cadena, separadas por punto. Limpia puntuación final duplicada.\n",
        "\n",
        "    - Si no hay pasos o no es una lista de strings, pone resumen = \"\".\n",
        "    - Devuelve el propio diccionario (mutado) por conveniencia.\n",
        "    \"\"\"\n",
        "    pasos = receta.get(clave_pasos) or []\n",
        "    if not isinstance(pasos, list):\n",
        "        receta[clave_resumen] = \"\"\n",
        "        return receta\n",
        "\n",
        "    limpios: List[str] = []\n",
        "    for p in pasos:\n",
        "        if not isinstance(p, str):\n",
        "            continue\n",
        "        s = p.strip()\n",
        "        # quita puntuación final para evitar \"..\"\n",
        "        s = re.sub(r\"\\s*([.;:!?…]+)\\s*$\", \"\", s)\n",
        "        if s:\n",
        "            limpios.append(s)\n",
        "\n",
        "    # une con \". \" y añade punto final si hay contenido\n",
        "    resumen = \". \".join(limpios)\n",
        "    if resumen:\n",
        "        resumen += \".\"\n",
        "    receta[clave_resumen] = resumen\n",
        "    return receta"
      ],
      "metadata": {
        "id": "UGa16e5s1Vyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for receta in recetas_cargadas:\n",
        "  receta = agregar_resumen_a_receta(receta)"
      ],
      "metadata": {
        "id": "qMs5MJUlAfsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A modo de ejemplo se muestra la receta 'Pollo crujiente con salsa césar', con el resumen incorporado"
      ],
      "metadata": {
        "id": "hbn8W6WieZkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recetas_cargadas[1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMjEsnERO-v8",
        "outputId": "7c56afa4-cfe5-4ad4-e3b0-0b240596c2d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'titulo': 'Pollo crujiente con salsa césar',\n",
              " 'url': 'https://recetasdecocina.elmundo.es/2012/08/pollo-crujiente-con-salsa-cesar.html',\n",
              " 'ingredientes': ['frutos secos',\n",
              "  'solomillo de pollo',\n",
              "  'sal',\n",
              "  'pimienta',\n",
              "  'huevo',\n",
              "  'aceite'],\n",
              " 'pasos': ['Ponemos los frutos secos dentro de un paño limpio de cocina y machamos hasta dejarlo en trocitos pequeños.',\n",
              "  'Batimos un huevo y rebozamos los solomillos de pollo, previamente salpimentados.',\n",
              "  'Los freímos en abundante aceite caliente y servimos acompañándolos con la salsa césar.'],\n",
              " 'resumen': 'Ponemos los frutos secos dentro de un paño limpio de cocina y machamos hasta dejarlo en trocitos pequeños. Batimos un huevo y rebozamos los solomillos de pollo, previamente salpimentados. Los freímos en abundante aceite caliente y servimos acompañándolos con la salsa césar.'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El siguiente paso consiste en el procesamiento y normalización del dataset para garantizar su compatibilidad con el pipeline de entrenamiento, que nos permitirá obtener  las etiquetas (ingredientes) y su posición en el texto. Este servirá de input para entrenar el modelo NER.\n",
        "\n",
        "Para ello, se implementan las siguientes funciones:. Para ello se definen las funciones:\n",
        "\n",
        "- ***_quitar_tildes***: devuelve el texto  sin tildes/diacríticos y mantiene el resto igual.\n",
        "\n",
        "- ***_build_norm_index_map***: genera la versión normalizada (minúsculas y sin tildes) de original y un mapa que indica, para cada carácter normalizado, qué índice tenía en el texto original.\n",
        "\n",
        "- ***_plural_es_basico***: aplica reglas simples de español para obtener el plural de una palabra (z→ces, vocal→+s, resto→+es; s/x suelen quedar igual).\n",
        "\n",
        "- ***_plural_de_frase***: pluraliza solo la última palabra “de contenido” de la frase (saltándose stopwords finales) usando _plural_es_basico.\n",
        "\n",
        "- ***asociar_ingredientes_en_resumen***: busca en el 'resumen' de la receta cada ingrediente (y, si procede, su plural), ignorando tildes y con opción de límites de palabra, y añade a la receta la lista deduplicada de ingredientes encontrados y sus spans (start, end, surface). Con ello obtendremos de cada receta los ingredientes correctamente etiquetados y posicionados."
      ],
      "metadata": {
        "id": "D7JX6Gy40_yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re, unicodedata\n",
        "from typing import Tuple\n",
        "\n",
        "_STOPWORDS = {\"de\",\"del\",\"la\",\"el\",\"las\",\"los\",\"al\",\"y\",\"en\",\"con\",\"para\"}\n",
        "\n",
        "def _quitar_tildes(txt: str) -> str:\n",
        "    return \"\".join(c for c in unicodedata.normalize(\"NFD\", txt) if unicodedata.category(c) != \"Mn\")\n",
        "\n",
        "def _build_norm_index_map(original: str) -> Tuple[str, List[int]]:\n",
        "    \"\"\"\n",
        "    Devuelve (texto_normalizado, idx_map) donde idx_map[i] es el índice del\n",
        "    carácter original correspondiente al carácter normalizado i.\n",
        "    \"\"\"\n",
        "    norm_chars, idx_map = [], []\n",
        "    for i, ch in enumerate(original):\n",
        "        base = _quitar_tildes(ch).lower()\n",
        "        for _ in base:\n",
        "            norm_chars.append(_)\n",
        "            idx_map.append(i)\n",
        "    return \"\".join(norm_chars), idx_map\n",
        "\n",
        "def _plural_es_basico(pal: str) -> str:\n",
        "    w = _quitar_tildes(pal.lower())\n",
        "    if not w:\n",
        "        return w\n",
        "    if w.endswith(\"z\"):\n",
        "        return w[:-1] + \"ces\"\n",
        "    if w.endswith((\"s\",\"x\")):\n",
        "        return w  # heurística: la mayoría quedan invariables\n",
        "    if re.search(r\"[aeiou]$\", w):\n",
        "        return w + \"s\"\n",
        "    return w + \"es\"\n",
        "\n",
        "def _plural_de_frase(ing: str) -> str:\n",
        "    toks = ing.lower().split()\n",
        "    if not toks:\n",
        "        return ing.lower()\n",
        "    idx = len(toks) - 1\n",
        "    while idx >= 0 and toks[idx] in _STOPWORDS:\n",
        "        idx -= 1\n",
        "    if idx < 0:\n",
        "        return ing.lower()\n",
        "    toks[idx] = _plural_es_basico(toks[idx])\n",
        "    return \" \".join(toks)\n",
        "\n",
        "def asociar_ingredientes_en_resumen(\n",
        "    receta: Dict[str, Any],\n",
        "    usar_limites_palabra: bool = True,\n",
        "    detectar_plural: bool = True\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Si un ingrediente (en singular) está en receta['resumen'],\n",
        "    lo asocia. También captura el plural (heurístico) y es insensible a tildes.\n",
        "    Añade:\n",
        "      - receta['ingredientes_en_resumen'] (lista deduplicada)\n",
        "      - receta['spans_resumen'] con {ingredient, start, end, surface}\n",
        "    Offsets 0-based sobre el resumen original. 'end' exclusivo.\n",
        "    \"\"\"\n",
        "    resumen = (receta.get(\"resumen\") or \"\")\n",
        "    ingredientes = receta.get(\"ingredientes\") or []\n",
        "    if not isinstance(resumen, str) or not isinstance(ingredientes, list):\n",
        "        receta[\"ingredientes_en_resumen\"] = []\n",
        "        receta[\"spans_resumen\"] = []\n",
        "        return receta\n",
        "\n",
        "    # Texto normalizado + mapa a original (insensible a tildes)\n",
        "    resumen_norm, idx_map = _build_norm_index_map(resumen)\n",
        "\n",
        "    presentes: List[str] = []\n",
        "    spans: List[Dict[str, Any]] = []\n",
        "\n",
        "    for ing in ingredientes:\n",
        "        ing_sing = (ing or \"\").strip()\n",
        "        if not ing_sing:\n",
        "            continue\n",
        "\n",
        "        # variantes: singular + plural (heurístico)\n",
        "        variantes = [ing_sing]\n",
        "        if detectar_plural:\n",
        "            pl = _plural_de_frase(ing_sing)\n",
        "            if pl and pl != ing_sing:\n",
        "                variantes.append(pl)\n",
        "\n",
        "        # buscamos cada variante sobre el texto normalizado\n",
        "        seen_positions = set()\n",
        "        for var in variantes:\n",
        "            var_norm = _quitar_tildes(var).lower()\n",
        "            if not var_norm:\n",
        "                continue\n",
        "\n",
        "            if usar_limites_palabra:\n",
        "                pat = re.compile(rf\"(?<!\\w){re.escape(var_norm)}(?!\\w)\")\n",
        "                matches = list(pat.finditer(resumen_norm))\n",
        "                if matches and ing_sing not in presentes:\n",
        "                    presentes.append(ing_sing)\n",
        "                for m in matches:\n",
        "                    s_n, e_n = m.span()\n",
        "                    s = idx_map[s_n]\n",
        "                    e = idx_map[e_n - 1] + 1\n",
        "                    if (s, e) in seen_positions:\n",
        "                        continue\n",
        "                    seen_positions.add((s, e))\n",
        "                    spans.append({\n",
        "                        \"ingredient\": ing_sing,\n",
        "                        \"start\": s,\n",
        "                        \"end\": e,\n",
        "                        \"surface\": resumen[s:e]\n",
        "                    })\n",
        "            else:\n",
        "                start_n = 0\n",
        "                found = False\n",
        "                while True:\n",
        "                    idx_n = resumen_norm.find(var_norm, start_n)\n",
        "                    if idx_n == -1:\n",
        "                        break\n",
        "                    s = idx_map[idx_n]\n",
        "                    e = idx_map[idx_n + len(var_norm) - 1] + 1\n",
        "                    if (s, e) not in seen_positions:\n",
        "                        seen_positions.add((s, e))\n",
        "                        spans.append({\n",
        "                            \"ingredient\": ing_sing,\n",
        "                            \"start\": s,\n",
        "                            \"end\": e,\n",
        "                            \"surface\": resumen[s:e]\n",
        "                        })\n",
        "                        found = True\n",
        "                    start_n = idx_n + len(var_norm)\n",
        "                if found and ing_sing not in presentes:\n",
        "                    presentes.append(ing_sing)\n",
        "\n",
        "    # deduplicar presentes manteniendo orden\n",
        "    seen_ing = set()\n",
        "    presentes = [x for x in presentes if not (x in seen_ing or seen_ing.add(x))]\n",
        "\n",
        "    receta[\"ingredientes_en_resumen\"] = presentes\n",
        "    receta[\"spans_resumen\"] = sorted(spans, key=lambda s: (s[\"start\"], s[\"end\"]))\n",
        "    return receta\n"
      ],
      "metadata": {
        "id": "tI2dhbcF3btS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A modo de ejemplo se muestra una entrada de la lista, correspondiente a la receta \"Pochas con pollo de corral\", una vez normalizada."
      ],
      "metadata": {
        "id": "CulnckBjIZ0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for receta in recetas_cargadas:\n",
        "  asociar_ingredientes_en_resumen(receta,usar_limites_palabra=True)"
      ],
      "metadata": {
        "id": "W_zm_tfKAvfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recetas_cargadas[1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lK_FDKmaPohB",
        "outputId": "14fe1924-9402-409a-8375-3f8d052d1276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'titulo': 'Pollo crujiente con salsa césar',\n",
              " 'url': 'https://recetasdecocina.elmundo.es/2012/08/pollo-crujiente-con-salsa-cesar.html',\n",
              " 'ingredientes': ['frutos secos',\n",
              "  'solomillo de pollo',\n",
              "  'sal',\n",
              "  'pimienta',\n",
              "  'huevo',\n",
              "  'aceite'],\n",
              " 'pasos': ['Ponemos los frutos secos dentro de un paño limpio de cocina y machamos hasta dejarlo en trocitos pequeños.',\n",
              "  'Batimos un huevo y rebozamos los solomillos de pollo, previamente salpimentados.',\n",
              "  'Los freímos en abundante aceite caliente y servimos acompañándolos con la salsa césar.'],\n",
              " 'resumen': 'Ponemos los frutos secos dentro de un paño limpio de cocina y machamos hasta dejarlo en trocitos pequeños. Batimos un huevo y rebozamos los solomillos de pollo, previamente salpimentados. Los freímos en abundante aceite caliente y servimos acompañándolos con la salsa césar.',\n",
              " 'ingredientes_en_resumen': ['frutos secos', 'huevo', 'aceite'],\n",
              " 'spans_resumen': [{'ingredient': 'frutos secos',\n",
              "   'start': 12,\n",
              "   'end': 24,\n",
              "   'surface': 'frutos secos'},\n",
              "  {'ingredient': 'huevo', 'start': 118, 'end': 123, 'surface': 'huevo'},\n",
              "  {'ingredient': 'aceite', 'start': 213, 'end': 219, 'surface': 'aceite'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dado que no todos los ingredientes presentan una frecuencia de aparición suficiente para garantizar un entrenamiento estadísticamente robusto de sus etiquetas, se establece un umbral mínimo de 50 ocurrencias. Únicamente se considerarán para el entrenamiento aquellos ingredientes cuya frecuencia supere dicho umbral.\n",
        "\n",
        "Para ello, se implementa la función ***top_ingredientes_frecuentes*** que filtra y retorna el conjunto de ingredientes con más de 50 apariciones en el dataset."
      ],
      "metadata": {
        "id": "Sp-BMBxMPn1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "def top_ingredientes_frecuentes(\n",
        "    recetas: List[Dict[str, Any]],\n",
        "    umbral: int = 50,\n",
        "    clave_spans: str = \"spans_resumen\",\n",
        "    clave_ing: str = \"ingredient\"\n",
        ") -> List[str]:\n",
        "    \"\"\"\n",
        "    Cuenta menciones por ingrediente a partir de 'spans_resumen' y\n",
        "    devuelve una lista de ingredientes (strings) que superan el umbral.\n",
        "    - 'umbral' aplica como '>' (estrictamente mayor que).\n",
        "    \"\"\"\n",
        "    c = Counter()\n",
        "    for r in recetas:\n",
        "        for s in (r.get(clave_spans) or []):\n",
        "            ing = s.get(clave_ing)\n",
        "            if ing:\n",
        "                c[ing] += 1\n",
        "\n",
        "    # filtrar > umbral y ordenar desc por conteo, luego alfabético\n",
        "    filtrados = [(ing, n) for ing, n in c.items() if n > umbral]\n",
        "    ordenados = sorted(filtrados, key=lambda x: (-x[1], x[0]))\n",
        "    return [ing for ing, _ in ordenados]"
      ],
      "metadata": {
        "id": "zpM2CR9iClS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ingredientes_frecuentes = top_ingredientes_frecuentes(recetas_cargadas)\n",
        "print(ingredientes_frecuentes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o98qqfLgDO4b",
        "outputId": "b8260f53-263b-4446-844f-a2a06bdde3e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sal', 'ajo', 'cebolla', 'patata', 'aceite de oliva', 'huevo', 'tomate', 'pollo', 'harina', 'agua', 'perejil', 'arroz', 'leche', 'mantequilla', 'zanahoria', 'azúcar', 'pimentón', 'aceite', 'puerro', 'pimiento', 'bacalao', 'vino blanco', 'nata', 'pan', 'salmón', 'caldo de pollo', 'cebolleta', 'vinagre', 'caldo', 'pasta', 'queso', 'limón', 'pimienta', 'caldo de pescado', 'merluza', 'calabacín', 'garbanzo', 'atún']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filtramos las recetas de manera que el span solo se haga con los ingredientes de la lista top_frecuentes. Si una receta no contiene ninguno de esos ingredientes se elimina\n",
        "\n",
        "Con la función ***filtrar_spans_por_frecuentes***. Filtramos las recetas de manera que el span solo se haga con los ingredientes de la lista top_frecuentes. Si una receta no contiene ninguno de esos ingredientes se elimina del corpus de entrenamiento."
      ],
      "metadata": {
        "id": "eSM5s1cHQKpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections.abc import Iterable\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "def filtrar_spans_por_frecuentes(\n",
        "    recetas: List[Dict[str, Any]],\n",
        "    ingredientes_frecuentes: Iterable,  # [\"tomate\", ...] o [(\"tomate\", 123), ...]\n",
        "    clave_spans: str = \"spans_resumen\",\n",
        "    clave_ing: str = \"ingredient\",\n",
        "    actualizar_ingredientes_en_resumen: bool = True,\n",
        "    eliminar_recetas_sin_spans: bool = False,\n",
        "    eliminar_si_ingredientes_en_resumen_vacio: bool = True\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Mantiene en cada receta solo los spans cuyo 'ingredient' esté en 'ingredientes_frecuentes'.\n",
        "    - Si 'actualizar_ingredientes_en_resumen' es True, recalcula esa lista con los spans filtrados.\n",
        "    - Si 'eliminar_recetas_sin_spans' es True, descarta recetas sin spans tras filtrar.\n",
        "    - Si 'eliminar_si_ingredientes_en_resumen_vacio' es True, descarta recetas cuyo\n",
        "      'ingredientes_en_resumen' quede vacío o nulo tras el filtrado.\n",
        "    Devuelve una **nueva lista** (no modifica la original).\n",
        "    \"\"\"\n",
        "    # Normaliza lista de permitidos a set de strings\n",
        "    allowed = set()\n",
        "    for x in ingredientes_frecuentes or []:\n",
        "        name = x[0] if isinstance(x, (list, tuple)) else x\n",
        "        if isinstance(name, str) and name.strip():\n",
        "            allowed.add(name.strip())\n",
        "\n",
        "    nuevas_recetas: List[Dict[str, Any]] = []\n",
        "    for r in recetas:\n",
        "        spans = r.get(clave_spans) or []\n",
        "        filtrados = [s for s in spans\n",
        "                     if isinstance(s, dict) and s.get(clave_ing) in allowed]\n",
        "\n",
        "        # Clona receta y escribe spans filtrados\n",
        "        r2 = dict(r)\n",
        "        r2[clave_spans] = sorted(\n",
        "            filtrados, key=lambda s: (s.get(\"start\", 0), s.get(\"end\", 0))\n",
        "        )\n",
        "\n",
        "        # Actualiza lista de ingredientes_en_resumen a partir de los spans filtrados\n",
        "        if actualizar_ingredientes_en_resumen:\n",
        "            vistos = set()\n",
        "            ing_list = []\n",
        "            for s in r2[clave_spans]:\n",
        "                lab = s.get(clave_ing)\n",
        "                if lab and lab not in vistos:\n",
        "                    vistos.add(lab)\n",
        "                    ing_list.append(lab)\n",
        "            r2[\"ingredientes_en_resumen\"] = ing_list\n",
        "\n",
        "        # Eliminaciones opcionales\n",
        "        if eliminar_recetas_sin_spans and not r2[clave_spans]:\n",
        "            continue\n",
        "\n",
        "        if eliminar_si_ingredientes_en_resumen_vacio:\n",
        "            ing_res = r2.get(\"ingredientes_en_resumen\")\n",
        "            if not ing_res:  # None, [], \"\", etc. se consideran vacíos\n",
        "                continue\n",
        "\n",
        "        nuevas_recetas.append(r2)\n",
        "\n",
        "    return nuevas_recetas"
      ],
      "metadata": {
        "id": "ukPOEOByHZks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recetas_filtradas = filtrar_spans_por_frecuentes(recetas_cargadas, ingredientes_frecuentes=ingredientes_frecuentes)"
      ],
      "metadata": {
        "id": "dLwje5PZHdQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El tamaño del dataset apenas se ve reducido tras preprocesarlo.\n"
      ],
      "metadata": {
        "id": "atFdQHWzN3cD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(recetas_filtradas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSkO6Y2nHuSG",
        "outputId": "16c1efc3-8cce-4ed8-f0f5-50d10dd78266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1104"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para terminar con el modulo de preprocesamiento,reestructuramos los diccionarios para adaptarlos al formato requerido por los modelos de NER multiclase. Para ello utilizamos las siguientes funciones:\n",
        "\n",
        "- ***_resolve_overlaps_longest:*** ordena los spans por inicio y longitud (más largos primero por posición) y elimina solapamientos quedándose con la secuencia no solapada que prioriza el span más largo.\n",
        "\n",
        "- ***recetas_a_ner_multiclase:*** transforma las recetas en ejemplos de NER multiclase usando cada ingredient como etiqueta, opcionalmente resuelve solapes, valida offsets, y devuelve la lista de ejemplos {id, text, entities} junto con el conjunto ordenado de etiquetas"
      ],
      "metadata": {
        "id": "oqk_6GB8Qb_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _resolve_overlaps_longest(spans):\n",
        "    if not spans: return []\n",
        "    spans = sorted(spans, key=lambda s: (s[\"start\"], -(s[\"end\"]-s[\"start\"])))\n",
        "    out = []\n",
        "    for s in spans:\n",
        "        if not out or s[\"start\"] >= out[-1][\"end\"]:\n",
        "            out.append(s)\n",
        "        # si solapa, se queda el previo (más largo, ya que ordenamos por longitud desc)\n",
        "    return out\n",
        "\n",
        "def recetas_a_ner_multiclase(recetas, resolver_solapes=True):\n",
        "    \"\"\"\n",
        "    Usa el campo 'ingredient' de cada span como label (ya normalizado).\n",
        "    Formato de salida: [{id, text, entities:[{start,end,label}, ...]}, ...]\n",
        "    \"\"\"\n",
        "    ejemplos = []\n",
        "    label_set = set()\n",
        "\n",
        "    for i, r in enumerate(recetas, 1):\n",
        "        text = r.get(\"resumen\") or \"\"\n",
        "        spans = r.get(\"spans_resumen\") or []\n",
        "        use = _resolve_overlaps_longest(spans) if resolver_solapes else sorted(spans, key=lambda s:(s[\"start\"], s[\"end\"]))\n",
        "\n",
        "        entities = []\n",
        "        for s in use:\n",
        "            start, end = int(s[\"start\"]), int(s[\"end\"])\n",
        "            # validación suave de offsets\n",
        "            surface = text[start:end]\n",
        "            if \"surface\" in s and s[\"surface\"] != surface:\n",
        "                # si no cuadra, puedes loguear o continuar\n",
        "                pass\n",
        "            lab = s.get(\"ingredient\", \"\")\n",
        "            if not lab:\n",
        "                continue\n",
        "            entities.append({\"start\": start, \"end\": end, \"label\": lab})\n",
        "            label_set.add(lab)\n",
        "\n",
        "        ejemplos.append({\n",
        "            \"id\": r.get(\"id\", f\"receta_{i:05d}\"),\n",
        "            \"text\": text,\n",
        "            \"entities\": entities\n",
        "        })\n",
        "\n",
        "    return ejemplos, sorted(label_set)"
      ],
      "metadata": {
        "id": "F9urDG0kSyiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardamos el dataset de entrenamiento del modelo NER."
      ],
      "metadata": {
        "id": "1wxy8WpPPf1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, labels = recetas_a_ner_multiclase(recetas_filtradas)"
      ],
      "metadata": {
        "id": "O0wb6KdvVewB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#guardamos el dataset que servirá de entrenamiento (+ validacion + test) del modelo NER\n",
        "Path(\"train_data.json\").write_text(\n",
        "    json.dumps(train_data, ensure_ascii=False, indent=2),\n",
        "    encoding=\"utf-8\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoTJY0QnNkJR",
        "outputId": "6192945b-c537-4831-a52c-092044ec57a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1296821"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Leerlo de vuelta para chequear que todo esta bien\n",
        "contenido = Path(\"train_data.json\").read_text(encoding=\"utf-8\")\n",
        "data_train = json.loads(contenido)"
      ],
      "metadata": {
        "id": "BL10sLSuVn2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A modo de ejemplo se muestra uan entrada del dataset de entrenamiento."
      ],
      "metadata": {
        "id": "CCQqZVlnPt3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_train[922]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2flWRQEOe-I",
        "outputId": "a35b5adb-aa38-4229-cac0-1003d63df66d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 'receta_00923',\n",
              " 'text': 'La salsa es tan sencilla como poner todo los ingredientes a fuego lento y dejar que se vayan ligando. Pasados unos 5 minutos añadimos el pollo cortado en dados. Seguidamente las verduras cortadas como veis en la foto. Dejamos cocinar durante unos 10-15 minutos a fuego medio y listo. Cocemos arroz tailandes largo para acompañar el plato, fundamental porque pica mucho y os calmará! jejeje.',\n",
              " 'entities': [{'start': 137, 'end': 142, 'label': 'pollo'},\n",
              "  {'start': 292, 'end': 297, 'label': 'arroz'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}
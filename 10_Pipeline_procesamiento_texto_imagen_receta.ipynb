{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **10. Pipeline** **de** **procesamiento** **de** **texto** **e** **imagen** **de** **la** **receta**\n",
        "\n",
        "Una vez desarrollada la funcionalidad de procesamiento de recetas con lenguaje natural y entrenado el modelo de procesamiento de imagenes, se define la pipeline de  asistencia virtual de cocina que las integra."
      ],
      "metadata": {
        "id": "MfhqVFXs0Lt7"
      },
      "id": "MfhqVFXs0Lt7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ada4e86",
      "metadata": {
        "id": "0ada4e86"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Set the environment variable within the notebook\n",
        "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Carga del modelo de detección de ingredientes, '*best_new_6.pt*'."
      ],
      "metadata": {
        "id": "e7LEVp0n1WUc"
      },
      "id": "e7LEVp0n1WUc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "504c82c0",
      "metadata": {
        "id": "504c82c0"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "model = YOLO(r'C:\\Users\\Javier Ponsin\\Desktop\\Jorge\\Ingredients-detection-YoloV8-1\\best_new_6.pt')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Carga del input a utilizar en la pipeline del demostrador de la aplicación. Este input corresponde a una receta de tortilla de patatas procesada previamente mediante el módulo de lenguaje natural, a fin de extraer los pasos y los ingredientes asociados a cada uno."
      ],
      "metadata": {
        "id": "MXS9Qsgg1jri"
      },
      "id": "MXS9Qsgg1jri"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "590820ee-cc38-4312-8c32-d229d5ad7d0c",
      "metadata": {
        "id": "590820ee-cc38-4312-8c32-d229d5ad7d0c"
      },
      "outputs": [],
      "source": [
        "receta_tortilla = {'pasos': ['Pelamos las patatas y las cortamos en gajos finos.', 'Picamos la cebolla en trocitos.', 'Mezclamos las patatas con la cebolla en la sarten y lo freimos.', 'Una vez pochada las patatas y la cebolla, lo mezclamos con el huevo batido.', 'Por ultimo ponemos la mezcla en la sarten'], 'ingredientes': [['patata'], ['cebolla'], ['patata', 'cebolla'], ['patata', 'cebolla', 'huevo'], []]}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Dado que las etiquetas usadas para el modelo de lenguaje están en castellano y las del modelo YOLO en inglés, es necesario definir un diccionario que las relacione. Simplificamos el diccionario incluyendo solo aquellos ingredientes  comunes al procesador de texto y al de imagen.\n",
        "\n",
        "Definimos la función ***traducir_ingredientes*** que añade una entrada a la receta con los ingredientes traducidos al inglés."
      ],
      "metadata": {
        "id": "NvBN8DNH3gj8"
      },
      "id": "NvBN8DNH3gj8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a5269ee-f5c4-45c3-911f-b76a406b9d9f",
      "metadata": {
        "id": "8a5269ee-f5c4-45c3-911f-b76a406b9d9f"
      },
      "outputs": [],
      "source": [
        "traductor = {\n",
        "    'patata': 'potato',\n",
        "    'cebolla': 'onion',\n",
        "    'huevo': 'egg',\n",
        "    'leche': 'milk',\n",
        "    'limon': 'lemon',\n",
        "    'pan': 'bread',\n",
        "    'pasta': 'pasta',\n",
        "    'queso': 'cheese',\n",
        "    'tomate': 'tomato',\n",
        "    'zanahoria': 'carrot',\n",
        "    'calabacin': 'zucchini'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2da56ceb-77ad-4581-b17b-2a934d950c02",
      "metadata": {
        "id": "2da56ceb-77ad-4581-b17b-2a934d950c02"
      },
      "outputs": [],
      "source": [
        "def traducir_ingredientes(receta, traductor):\n",
        "\n",
        "    # Traduce cada sublista de ingredientes usando el diccionario\n",
        "    ingredientes_en_ingles = []\n",
        "    for lista in receta['ingredientes']:\n",
        "        traducidos = [traductor.get(ing, ing) for ing in lista]  # Si no existe en traductor, deja el original\n",
        "        ingredientes_en_ingles.append(traducidos)\n",
        "\n",
        "    # Añade nueva clave con la traducción\n",
        "    receta['ingredients'] = ingredientes_en_ingles\n",
        "    return receta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "928e1b0c-ae51-4f38-9061-32094bdf3bb8",
      "metadata": {
        "id": "928e1b0c-ae51-4f38-9061-32094bdf3bb8",
        "outputId": "905ca500-df13-4a4c-b7ae-3f6f9731850a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'pasos': ['Pelamos las patatas y las cortamos en gajos finos.', 'Picamos la cebolla en trocitos.', 'Mezclamos las patatas con la cebolla en la sarten y lo freimos.', 'Una vez pochada las patatas y la cebolla, lo mezclamos con el huevo batido.', 'Por ultimo ponemos la mezcla en la sarten'], 'ingredientes': [['patata'], ['cebolla'], ['patata', 'cebolla'], ['patata', 'cebolla', 'huevo'], []], 'ingredients': [['potato'], ['onion'], ['potato', 'onion'], ['potato', 'onion', 'egg'], []]}\n"
          ]
        }
      ],
      "source": [
        "traducir_ingredientes(receta_tortilla, traductor)\n",
        "print(receta_tortilla)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. **Definición del algoritmo de asistencia de video y texto para recetas de cocina:**\n",
        "\n",
        "El algoritmo propuesto se basa en sincronizar el avance de la receta mediante los ingredientes detectados en cada fotograma, intentando interpretar en cada instante en qué paso de la receta se encuentra el cocinero, mostrándole por pantalla al mismo el paso en el que se encuentra y el siguiente paso.\n",
        "\n",
        "Para construir este algoritmo, se definen las siguientes funciones:\n",
        "\n",
        "- *show_frame*: elige automáticamente el método adecuado para procesar la imagen según si la ejecución ocurre en Google Colab o en un entorno local.\n",
        "- *_wrap_text*: divide un texto en varias líneas asegurando que cada una no exceda el ancho máximo. Se utiliza para definir el formato utilizado en *'show_pasos'*.\n",
        "- *show_pasos*: genera y muestra una ventana en la que se visualizan, de forma formateada en texto, el paso actual y el siguiente de una receta.\n",
        "\n",
        "Estas funciones se implementan en un bucle while, que es el núcleo del asistente en tiempo real. Este bucle  recorre el video frame a frame obteniendo mediante el modelo YOLO los ingredientes que aparecen en el mismo. Si en el frame detecta alguno perteneciente al siguiente paso de la receta, avanza el índice para actualizar el paso de la receta. La pantall de asistencia a la cocina se actualiza con los nuevos pasos actual y siguiente."
      ],
      "metadata": {
        "id": "wqaBNQfl4lWS"
      },
      "id": "wqaBNQfl4lWS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1a1964d-77ef-4714-b00f-3cb392697c26",
      "metadata": {
        "id": "c1a1964d-77ef-4714-b00f-3cb392697c26"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def show_frame(img):\n",
        "\n",
        "    try:\n",
        "        from google.colab.patches import cv2_imshow\n",
        "        from IPython.display import clear_output\n",
        "        clear_output(wait=True)  # Clear output para evitar acumulación de imágenes\n",
        "        cv2_imshow(img)\n",
        "    except ImportError:\n",
        "        cv2.imshow(\"YOLOv8 Tracking\", img)\n",
        "\n",
        "def _wrap_text(text, max_width, font, scale, thickness):\n",
        "    \"\"\"Parte el texto en líneas que quepan dentro de max_width (medido con cv2).\"\"\"\n",
        "    words = text.split()\n",
        "    lines, cur = [], \"\"\n",
        "    for w in words:\n",
        "        test = (cur + \" \" + w).strip()\n",
        "        (wpx, _), _ = cv2.getTextSize(test, font, scale, thickness)\n",
        "        if wpx <= max_width:\n",
        "            cur = test\n",
        "        else:\n",
        "            if cur:\n",
        "                lines.append(cur)\n",
        "            cur = w\n",
        "    if cur:\n",
        "        lines.append(cur)\n",
        "    return lines\n",
        "\n",
        "def show_pasos(texto_paso_1, texto_paso_2, window_title=\"Pasos\"):\n",
        "\n",
        "    # Lienzo\n",
        "    img_h, img_w = 420, 800\n",
        "    img = np.ones((img_h, img_w, 3), dtype=np.uint8) * 255\n",
        "\n",
        "    # Estilos\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    scale_label = 0.85\n",
        "    scale_text  = 0.8\n",
        "    thick = 2\n",
        "    x0, y0 = 16, 40\n",
        "    line_gap = 8\n",
        "    (_, base_h), _ = cv2.getTextSize(\"Ag\", font, scale_text, thick)\n",
        "    line_h = base_h + line_gap\n",
        "    max_w = img_w - 2*x0\n",
        "\n",
        "    y = y0\n",
        "\n",
        "    # ---- Paso 1 ----\n",
        "    cv2.putText(img, \"Paso actual\", (x0, y), font, scale_label, (0,0,160), thick, cv2.LINE_AA)\n",
        "    y += int(line_h * 1.2)\n",
        "\n",
        "    for line in _wrap_text(texto_paso_1, max_w, font, scale_text, thick):\n",
        "        if y > img_h - 16:\n",
        "            cv2.putText(img, \"...\", (x0, img_h-10), font, scale_text, (0,0,0), thick, cv2.LINE_AA)\n",
        "            cv2.imshow(window_title, img)\n",
        "            return\n",
        "        cv2.putText(img, line, (x0, y), font, scale_text, (0,0,0), thick, cv2.LINE_AA)\n",
        "        y += line_h\n",
        "\n",
        "    y += int(line_h * 0.6)  # separación entre pasos\n",
        "\n",
        "    # ---- Paso 2 ----\n",
        "    cv2.putText(img, \"Siguiente paso\", (x0, y), font, scale_label, (0,0,160), thick, cv2.LINE_AA)\n",
        "    y += int(line_h * 1.2)\n",
        "\n",
        "    for line in _wrap_text(texto_paso_2, max_w, font, scale_text, thick):\n",
        "        if y > img_h - 16:\n",
        "            cv2.putText(img, \"...\", (x0, img_h-10), font, scale_text, (0,0,0), thick, cv2.LINE_AA)\n",
        "            break\n",
        "        cv2.putText(img, line, (x0, y), font, scale_text, (0,0,0), thick, cv2.LINE_AA)\n",
        "        y += line_h\n",
        "\n",
        "    cv2.imshow(window_title, img)\n",
        "\n",
        "# Ruta del video\n",
        "video = \"C:/Users/Javier Ponsin/Desktop/Jorge/Ingredients-detection-YoloV8-1/tortilla9.mp4\"\n",
        "\n",
        "# Abrimos el video\n",
        "cap = cv2.VideoCapture(video)\n",
        "\n",
        "i = 0\n",
        "paso = receta_tortilla['pasos'][i]\n",
        "ingredients = receta_tortilla['ingredients'][i]\n",
        "siguiente_paso = receta_tortilla['pasos'][i+1]\n",
        "\n",
        "while cap.isOpened():\n",
        "    success, frame = cap.read()\n",
        "\n",
        "    if success:\n",
        "        # Detección con YOLOv8\n",
        "        results = model.track(frame, persist=True, verbose=False)\n",
        "        result = results[0]\n",
        "\n",
        "        # Extraemos ingredientes detectados (clases)\n",
        "        if result.boxes.id is not None:\n",
        "\n",
        "            for c in result.boxes.cls:\n",
        "                ingredient = model.names[int(c)].lower()\n",
        "                if ingredient in ingredients:\n",
        "                    i = i\n",
        "                elif ingredient in receta_tortilla['ingredients'][i + 1]:\n",
        "                    i = i + 1\n",
        "                    paso = receta_tortilla['pasos'][i]\n",
        "                    siguiente_paso = receta_tortilla['pasos'][i+1]\n",
        "                    ingredients = receta_tortilla['ingredients'][i]\n",
        "\n",
        "\n",
        "        # Mostramos frame con anotaciones\n",
        "        annotated_frame = result.plot()\n",
        "        show_frame(annotated_frame)\n",
        "\n",
        "        # Mostramos ventana con ingredientes\n",
        "        show_pasos(paso,siguiente_paso)\n",
        "\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):  # Salir con 'q'\n",
        "            break\n",
        "    else:\n",
        "        break\n",
        "\n",
        "# Liberamos recursos\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Pipeline** **de** **procesamiento** **de** **texto** **en** **recetas**\n",
        "\n",
        "En este módulo se define el pipeline que va a utilizarse para procesar las recetas a partir de los modelos NER y clasificador  entrenados."
      ],
      "metadata": {
        "id": "fi-qsmCDSIcb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrfTmIVjSH_G",
        "outputId": "02f47919-ec1b-4cd4-9db2-bfd2562391c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  # autoriza en el popup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Carga del modelo clasificador de pasos y sus funciones asociadas (*_rm_acc*, *_build_norm_with_map*, *oraciones_con_offsets*, *_overlap*, *localizar_pasos_en_resumen*, *etiquetar_bi_por_oracion*, *construir_oraciones_dataset_bi*, *predecir_bi_por_oracion*, *reconstruir_pasos_desde_BI*)"
      ],
      "metadata": {
        "id": "W19w0WtgZa6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "LOAD_DIR = \"/content/drive/MyDrive/TFM/Classifier_model\"\n",
        "tokenizer_class = AutoTokenizer.from_pretrained(LOAD_DIR)\n",
        "modelo_class     = AutoModelForSequenceClassification.from_pretrained(LOAD_DIR)"
      ],
      "metadata": {
        "id": "arxNUf2USYtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re, unicodedata, numpy as np, torch\n",
        "from typing import List, Dict, Any, Tuple\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import DataCollatorWithPadding, TrainingArguments, Trainer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score"
      ],
      "metadata": {
        "id": "nATiloRnTveG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _rm_acc(s: str) -> str:\n",
        "    return \"\".join(c for c in unicodedata.normalize(\"NFD\", s) if unicodedata.category(c) != \"Mn\")\n",
        "\n",
        "def _build_norm_with_map(text: str):\n",
        "    \"\"\"Normaliza (minúsculas, sin tildes, colapsa espacios) + mapa a índices del original.\"\"\"\n",
        "    norm_chars, idx_map = [], []\n",
        "    last_space = False\n",
        "    for i, ch in enumerate(text):\n",
        "        base = _rm_acc(ch).lower()\n",
        "        if base.isspace():\n",
        "            if not last_space:\n",
        "                norm_chars.append(\" \")\n",
        "                idx_map.append(i)\n",
        "            last_space = True\n",
        "        else:\n",
        "            norm_chars.append(base)\n",
        "            idx_map.append(i)\n",
        "            last_space = False\n",
        "    norm = \" \".join(\"\".join(norm_chars).strip().split())\n",
        "    idx_map = idx_map[:len(norm)]\n",
        "    return norm, idx_map\n",
        "\n",
        "def oraciones_con_offsets(texto: str):\n",
        "    \"\"\"Divide por . ! ? …  y devuelve [(start,end,oración)] (end exclusivo).\"\"\"\n",
        "    bounds, start = [], 0\n",
        "    for m in re.finditer(r\"[.!?…]+\", texto):\n",
        "        end = m.end()\n",
        "        if end > start:\n",
        "            bounds.append((start, end))\n",
        "        nxt = end\n",
        "        while nxt < len(texto) and texto[nxt].isspace():\n",
        "            nxt += 1\n",
        "        start = nxt\n",
        "    if start < len(texto):\n",
        "        bounds.append((start, len(texto)))\n",
        "    return [(a,b,texto[a:b]) for a,b in bounds]\n",
        "\n",
        "def _overlap(a1,b1,a2,b2):\n",
        "    return max(0, min(b1,b2) - max(a1,a2))\n",
        "\n",
        "def localizar_pasos_en_resumen(resumen: str, pasos: List[str]):\n",
        "    \"\"\"Encuentra pasos en el resumen con búsqueda robusta (normalizada).\"\"\"\n",
        "    offs, cursor_norm = [], 0\n",
        "    H, Hmap = _build_norm_with_map(resumen)\n",
        "    for p in (pasos or []):\n",
        "        p = (p or \"\").strip()\n",
        "        if not p:\n",
        "            continue\n",
        "        N, _ = _build_norm_with_map(p)\n",
        "        if not N:\n",
        "            continue\n",
        "        pos = H.find(N, cursor_norm)\n",
        "        if pos == -1:\n",
        "            pos = H.find(N)\n",
        "            if pos == -1:\n",
        "                continue\n",
        "        try:\n",
        "            s = Hmap[pos]\n",
        "            e = Hmap[pos + len(N) - 1] + 1\n",
        "            offs.append((s, e))\n",
        "            cursor_norm = pos + len(N)\n",
        "        except Exception:\n",
        "            continue\n",
        "    return offs\n",
        "\n",
        "def etiquetar_bi_por_oracion(resumen: str, pasos: List[str]) -> List[str]:\n",
        "    \"\"\"\n",
        "    Etiqueta BI por oración:\n",
        "      - 'B' si empieza un paso (o cambia de paso),\n",
        "      - 'I' si continúa el mismo paso.\n",
        "    Si una oración no solapa con ningún paso, continúa el actual (o abre 'B' si es la primera).\n",
        "    \"\"\"\n",
        "    sents = oraciones_con_offsets(resumen)\n",
        "    steps = localizar_pasos_en_resumen(resumen, pasos)\n",
        "    if not sents:\n",
        "        return []\n",
        "    asign = []\n",
        "    for (sa, sb, _) in sents:\n",
        "        best_k, best_ov = None, 0\n",
        "        for k, (pa, pb) in enumerate(steps):\n",
        "            ov = _overlap(sa, sb, pa, pb)\n",
        "            if ov > best_ov:\n",
        "                best_k, best_ov = k, ov\n",
        "        asign.append(best_k if best_ov > 0 else None)\n",
        "\n",
        "    labels, prev_step = [], None\n",
        "    for i, k in enumerate(asign):\n",
        "        if k is None:\n",
        "            k = prev_step if prev_step is not None else 0\n",
        "        labels.append(\"B\" if (prev_step is None or k != prev_step) else \"I\")\n",
        "        prev_step = k\n",
        "    return labels"
      ],
      "metadata": {
        "id": "8cF2sQZhUkZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def construir_oraciones_dataset_bi(recetas: List[Dict[str,Any]], usar_contexto: bool = True):\n",
        "    filas = []\n",
        "    for r in recetas:\n",
        "        resumen = (r.get(\"resumen\") or \"\").strip()\n",
        "        pasos   = r.get(\"pasos\") or []\n",
        "        if not resumen:\n",
        "            continue\n",
        "        sents = oraciones_con_offsets(resumen)\n",
        "        if not sents:\n",
        "            continue\n",
        "        labels = etiquetar_bi_por_oracion(resumen, pasos)\n",
        "        if len(labels) != len(sents):\n",
        "            labels = [\"I\"] * len(sents)  # fallback seguro\n",
        "\n",
        "        for i, (_,_,sent) in enumerate(sents):\n",
        "            row = {\"text\": sent, \"label\": labels[i]}\n",
        "            if usar_contexto:\n",
        "                row[\"prev\"] = sents[i-1][2] if i>0 else \"\"\n",
        "                row[\"next\"] = sents[i+1][2] if i < len(sents)-1 else \"\"\n",
        "            filas.append(row)\n",
        "    return filas"
      ],
      "metadata": {
        "id": "-o4N2q3gUrsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def predecir_bi_por_oracion(resumen: str, tokenizer, model, usar_contexto: bool = True):\n",
        "    model.eval()\n",
        "    sents = oraciones_con_offsets(resumen)\n",
        "    if not sents:\n",
        "        return []\n",
        "    textos = []\n",
        "    for i, (_,_,sent) in enumerate(sents):\n",
        "        if usar_contexto:\n",
        "            prev_txt = sents[i-1][2] if i>0 else \"\"\n",
        "            next_txt = sents[i+1][2] if i < len(sents)-1 else \"\"\n",
        "            sep = tokenizer.sep_token or \"</s>\"\n",
        "            textos.append(f\"{prev_txt.strip()} {sep} {sent.strip()} {sep} {next_txt.strip()}\".strip())\n",
        "        else:\n",
        "            textos.append(sent)\n",
        "    enc = tokenizer(textos, padding=True, truncation=True, max_length=256, return_tensors=\"pt\")\n",
        "    enc = {k: v.to(model.device) for k,v in enc.items()}\n",
        "    logits = model(**enc).logits\n",
        "    preds  = logits.argmax(-1).cpu().numpy().tolist()\n",
        "    return [id2label[i] for i in preds]  # \"B\" o \"I\"\n",
        "\n",
        "def reconstruir_pasos_desde_BI(resumen: str, etiquetas_bi: List[str]):\n",
        "    sents = oraciones_con_offsets(resumen)\n",
        "    assert len(sents) == len(etiquetas_bi)\n",
        "    pasos_offsets, pasos_textos = [], []\n",
        "    cur = None\n",
        "    def cerrar():\n",
        "        nonlocal cur\n",
        "        if cur:\n",
        "            a,b = cur\n",
        "            pasos_offsets.append((a,b))\n",
        "            pasos_textos.append(resumen[a:b])\n",
        "        cur = None\n",
        "    for (a,b,_), tag in zip(sents, etiquetas_bi):\n",
        "        tag = (tag or \"I\").upper()\n",
        "        if tag == \"B\" or cur is None:\n",
        "            cerrar(); cur = [a,b]\n",
        "        else:  # I\n",
        "            cur[1] = b\n",
        "    cerrar()\n",
        "    return {\"pasos\": pasos_textos, \"pasos_offsets\": pasos_offsets}\n"
      ],
      "metadata": {
        "id": "hYDAeMLRUvfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = [\"B\",\"I\"]\n",
        "label2id   = {\"B\":0, \"I\":1}\n",
        "id2label   = {0:\"B\", 1:\"I\"}"
      ],
      "metadata": {
        "id": "rJIaegoWU6h-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejemplo de salida al aplicar el modelo clasificador, con las entradas *'Etiquetas'* que clasifica cada frase según sea el inicio de un paso o la continuación del mismo, y la entrada *'Pasos'* que genera los pasos de la receta a partir de las etiquetas de las oraciones y su orden."
      ],
      "metadata": {
        "id": "YOMgkd2bbieP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto = (\"Pon en la olla ajo. Mezclalo con la cebolla. Despues añade el tomate\")\n",
        "y_bi = predecir_bi_por_oracion(texto, tokenizer_class, modelo_class, usar_contexto=True)\n",
        "seg  = reconstruir_pasos_desde_BI(texto, y_bi)\n",
        "print(\"Etiquetas:\", y_bi)            # p.ej. ['B','I','B']\n",
        "print(\"Pasos:\", seg[\"pasos\"])        # subcadenas EXACTAS del resumen\n",
        "print(\"Offsets:\", seg[\"pasos_offsets\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYGiMY_0TF-E",
        "outputId": "e6407f92-bf21-4b71-ed9e-72cf7ad56404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Etiquetas: ['B', 'I', 'B']\n",
            "Pasos: ['Pon en la olla ajo. Mezclalo con la cebolla.', 'Despues añade el tomate']\n",
            "Offsets: [(0, 44), (45, 68)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Carga del modelo NER de etiquetado de ingredientes."
      ],
      "metadata": {
        "id": "4V7dICBAcQmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "LOAD_DIR = \"/content/drive/MyDrive/TFM/ner_model_2\"\n",
        "tokenizer_ner = AutoTokenizer.from_pretrained(LOAD_DIR, use_fast=True)  # <- clave\n",
        "modelo_ner    = AutoModelForTokenClassification.from_pretrained(LOAD_DIR)"
      ],
      "metadata": {
        "id": "YOUWxqXnVGRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "clf = pipeline(\n",
        "    \"token-classification\",\n",
        "    model=modelo_ner,\n",
        "    tokenizer=tokenizer_ner,\n",
        "    aggregation_strategy=\"simple\",\n",
        "    device=0 if torch.cuda.is_available() else -1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9l3T4mDwWVE7",
        "outputId": "69e0c433-e432-4ca7-92d2-c6bc7fc3631c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Diseño del algoritmo de obtención de ingredientes por paso. Se aplica el modelo de reconocimiento de ingredientes sobre cada paso de la receta, previamente procesada con el clasificador de pasos. Los ingredientes se incluyen en listas asociadas a cada paso, que forman una lista con la receta completa. A modo de ejemplo se aplica a la receta definida antes."
      ],
      "metadata": {
        "id": "HjDlXTwrcCXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_por_paso = []\n",
        "\n",
        "for paso in seg.get(\"pasos\", []):\n",
        "    if isinstance(paso, str) and paso.strip():\n",
        "        ents = clf(paso)\n",
        "    else:\n",
        "        ents = []\n",
        "\n",
        "    labels = []\n",
        "    for e in ents:\n",
        "        lab = (e.get(\"entity_group\") or e.get(\"entity\") or \"\")\n",
        "        lab = lab.lower().replace(\"_\", \" \").strip()\n",
        "        if lab:\n",
        "            labels.append(lab)\n",
        "\n",
        "    labels_por_paso.append(labels)\n",
        "\n",
        "seg[\"labels_por_paso\"] = labels_por_paso"
      ],
      "metadata": {
        "id": "-YMl5KC4V8rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seg[\"labels_por_paso\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YVeqkvFbcE5",
        "outputId": "cbf50ed7-1071-4179-86e4-cf35ea276daa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['ajo', 'cebolla'], ['tomate']]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Integración del clasificador de pasos y el anotador de ingredientes mediante la función ***procesado_texto_receta***. El pipeline se basa en aplicar al conjunto del texto en crudo el clasificador para separarlos en pasos, y procesar paso a paso mediante el algoritmo anteriormente descrito obteniendo los ingredientes de cada paso."
      ],
      "metadata": {
        "id": "hgAvUPR3cJBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def procesado_texto_receta(receta):\n",
        "\n",
        "# 2) Segmentación BI -> pasos\n",
        "    y_bi = predecir_bi_por_oracion(texto, tokenizer_class, modelo_class, usar_contexto=True)\n",
        "    seg  = reconstruir_pasos_desde_BI(texto, y_bi)\n",
        "\n",
        "    # 3) NER por paso -> labels por paso\n",
        "    labels_por_paso = []\n",
        "    for paso in seg.get(\"pasos\", []):\n",
        "        if isinstance(paso, str) and paso.strip():\n",
        "            ents = clf(paso)  # pipeline(token-classification)\n",
        "        else:\n",
        "            ents = []\n",
        "\n",
        "        labels = []\n",
        "        for e in ents:\n",
        "            lab = (e.get(\"entity_group\") or e.get(\"entity\") or \"\")\n",
        "            lab = lab.lower().replace(\"_\", \" \").strip()\n",
        "            if lab:\n",
        "                labels.append(lab)\n",
        "        labels_por_paso.append(labels)\n",
        "\n",
        "    # 4) Construir salida\n",
        "    receta_procesada = {\n",
        "        \"pasos\": seg.get(\"pasos\", []),\n",
        "        \"ingredientes\": labels_por_paso\n",
        "    }\n",
        "    return receta_procesada"
      ],
      "metadata": {
        "id": "2WAR_LN3b9cU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probamos la función de procesado de recetas con distintas variaciones para valorar cualitativamente su desempeño."
      ],
      "metadata": {
        "id": "EI-l98FSi-ml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Pon en la olla ajo. Mezclalo con la cebolla. Despues añade el tomate\"\n",
        "receta_procesada_1 = procesado_texto_receta(texto)\n",
        "print(receta_procesada_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VayBmY3Kd8A2",
        "outputId": "f938281a-0f0e-4b8d-83aa-9b44167ee046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'pasos': ['Pon en la olla ajo. Mezclalo con la cebolla.', 'Despues añade el tomate'], 'ingredientes': [['ajo', 'cebolla'], ['tomate']]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = 'Ponemos los frutos secos dentro de un paño limpio de cocina y machamos hasta dejarlo en trocitos pequeños. Batimos un huevo y rebozamos los solomillos de pollo, previamente salpimentados. Los freímos en abundante aceite caliente y servimos acompañándolos con la salsa césar.'\n",
        "receta_procesada_2 = procesado_texto_receta(texto)\n",
        "print(receta_procesada_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i24hyfF4gCuI",
        "outputId": "e01640f0-15cf-4ba1-885d-3b4ffb45d766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'pasos': ['Ponemos los frutos secos dentro de un paño limpio de cocina y machamos hasta dejarlo en trocitos pequeños.', 'Batimos un huevo y rebozamos los solomillos de pollo, previamente salpimentados.', 'Los freímos en abundante aceite caliente y servimos acompañándolos con la salsa césar.'], 'ingredientes': [[], ['huevo', 'pollo'], ['aceite']]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Comenzamos haciendo la chistorra. La vamos a saltear en un sartén sin aceite ya que ella misma va a soltar mucha grasa.  Una vez cocida la retiramos y reservamos. Pelamos y partimos las patatas a lo largo. La freímos en abundante aceite de oliva. Ahora para hacer unos huevos de calidad, cogemos y cubrimos el fondo de una sartén con aceite de oliva. Cuando esté bien caliente, añadimos el huevo con un toque de sal por encima.  Con una espátula vamos echando por encima aceite para que se haga la yema un poco y listo. Sacamos el huevo y reservamos. Servimos las patatas con la chistorra y por encima el huevo frito y tenemos uno de los mejores platos de las abuelas.\"\n",
        "receta_procesada_3 = procesado_texto_receta(texto)\n",
        "print(receta_procesada_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNazZr62h3vC",
        "outputId": "b5b84d81-c9ef-4b3a-d6ea-bcbe09354151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'pasos': ['Comenzamos haciendo la chistorra.', 'La vamos a saltear en un sartén sin aceite ya que ella misma va a soltar mucha grasa.  Una vez cocida la retiramos y reservamos.', 'Pelamos y partimos las patatas a lo largo.', 'La freímos en abundante aceite de oliva.', 'Ahora para hacer unos huevos de calidad, cogemos y cubrimos el fondo de una sartén con aceite de oliva.', 'Cuando esté bien caliente, añadimos el huevo con un toque de sal por encima.', 'Con una espátula vamos echando por encima aceite para que se haga la yema un poco y listo. Sacamos el huevo y reservamos.', 'Servimos las patatas con la chistorra y por encima el huevo frito y tenemos uno de los mejores platos de las abuelas.'], 'ingredientes': [[], [], ['patata'], ['aceite'], ['huevo', 'aceite'], ['huevo', 'sal'], ['huevo'], ['patata', 'huevo']]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Receta Tortilla de patatas"
      ],
      "metadata": {
        "id": "A7a6tgouWX2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Pelamos las patatas y las cortamos en gajos finos. Picamos la cebolla en  trocitos . Mezclamos las patatas con la cebolla en la sarten y lo freímos. Una vez pochadada las patatas y la cebolla, lo mezclamos con el huevo batido. Por último ponemos la mezcla en la sarten\"\n",
        "receta_procesada_tortilla = procesado_texto_receta(texto)\n",
        "print(receta_procesada_tortilla)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2BooCfnWa5l",
        "outputId": "e3464ec2-7f03-4fe3-e39b-387eddaf62d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'pasos': ['Pelamos las patatas y las cortamos en gajos finos.', 'Picamos la cebolla en  trocitos .', 'Mezclamos las patatas con la cebolla en la sarten y lo freímos.', 'Una vez pochadada las patatas y la cebolla, lo mezclamos con el huevo batido.', 'Por último ponemos la mezcla en la sarten'], 'ingredientes': [['patata'], ['cebolla'], ['patata', 'cebolla'], ['patata', 'cebolla', 'huevo'], []]}\n"
          ]
        }
      ]
    }
  ]
}